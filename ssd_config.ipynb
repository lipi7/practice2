{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is a part of OpenCV project.\n",
    "# It is a subject to the license terms in the LICENSE file found in the top-level directory\n",
    "# of this distribution and at http://opencv.org/license.html.\n",
    "#\n",
    "# Copyright (C) 2018, Intel Corporation, all rights reserved.\n",
    "# Third party copyrights are property of their respective owners.\n",
    "#\n",
    "# Use this script to get the text graph representation (.pbtxt) of SSD-based\n",
    "# deep learning network trained in TensorFlow Object Detection API.\n",
    "# Then you can import it with a binary frozen graph (.pb) using readNetFromTensorflow() function.\n",
    "# See details and examples on the following wiki page: https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API\n",
    "import argparse\n",
    "import re\n",
    "from math import sqrt\n",
    "from tf_text_graph_common import *\n",
    "\n",
    "class SSDAnchorGenerator:\n",
    "    def __init__(self, min_scale, max_scale, num_layers, aspect_ratios,\n",
    "                 reduce_boxes_in_lowest_layer, image_width, image_height):\n",
    "        self.min_scale = min_scale\n",
    "        self.aspect_ratios = aspect_ratios\n",
    "        self.reduce_boxes_in_lowest_layer = reduce_boxes_in_lowest_layer\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.scales =  [min_scale + (max_scale - min_scale) * i / (num_layers - 1)\n",
    "                            for i in range(num_layers)] + [1.0]\n",
    "\n",
    "    def get(self, layer_id):\n",
    "        if layer_id == 0 and self.reduce_boxes_in_lowest_layer:\n",
    "            widths = [0.1, self.min_scale * sqrt(2.0), self.min_scale * sqrt(0.5)]\n",
    "            heights = [0.1, self.min_scale / sqrt(2.0), self.min_scale / sqrt(0.5)]\n",
    "        else:\n",
    "            widths = [self.scales[layer_id] * sqrt(ar) for ar in self.aspect_ratios]\n",
    "            heights = [self.scales[layer_id] / sqrt(ar) for ar in self.aspect_ratios]\n",
    "\n",
    "            widths += [sqrt(self.scales[layer_id] * self.scales[layer_id + 1])]\n",
    "            heights += [sqrt(self.scales[layer_id] * self.scales[layer_id + 1])]\n",
    "        min_size = min(self.image_width, self.image_height)\n",
    "        widths = [w * min_size for w in widths]\n",
    "        heights = [h * min_size for h in heights]\n",
    "        return widths, heights\n",
    "\n",
    "\n",
    "class MultiscaleAnchorGenerator:\n",
    "    def __init__(self, min_level, aspect_ratios, scales_per_octave, anchor_scale):\n",
    "        self.min_level = min_level\n",
    "        self.aspect_ratios = aspect_ratios\n",
    "        self.anchor_scale = anchor_scale\n",
    "        self.scales = [2**(float(s) / scales_per_octave) for s in range(scales_per_octave)]\n",
    "\n",
    "    def get(self, layer_id):\n",
    "        widths = []\n",
    "        heights = []\n",
    "        for a in self.aspect_ratios:\n",
    "            for s in self.scales:\n",
    "                base_anchor_size = 2**(self.min_level + layer_id) * self.anchor_scale\n",
    "                ar = sqrt(a)\n",
    "                heights.append(base_anchor_size * s / ar)\n",
    "                widths.append(base_anchor_size * s * ar)\n",
    "        return widths, heights\n",
    "\n",
    "\n",
    "def createSSDGraph(modelPath, configPath, outputPath):\n",
    "    # Nodes that should be kept.\n",
    "    keepOps = ['Conv2D', 'BiasAdd', 'Add', 'AddV2', 'Relu', 'Relu6', 'Placeholder', 'FusedBatchNorm',\n",
    "               'DepthwiseConv2dNative', 'ConcatV2', 'Mul', 'MaxPool', 'AvgPool', 'Identity',\n",
    "               'Sub', 'ResizeNearestNeighbor', 'Pad', 'FusedBatchNormV3', 'Mean']\n",
    "\n",
    "    # Node with which prefixes should be removed\n",
    "    prefixesToRemove = ('MultipleGridAnchorGenerator/', 'Concatenate/', 'Postprocessor/', 'Preprocessor/map')\n",
    "\n",
    "    # Load a config file.\n",
    "    config = readTextMessage(configPath)\n",
    "    config = config['model'][0]['ssd'][0]\n",
    "    num_classes = int(config['num_classes'][0])\n",
    "\n",
    "    fixed_shape_resizer = config['image_resizer'][0]['fixed_shape_resizer'][0]\n",
    "    image_width = int(fixed_shape_resizer['width'][0])\n",
    "    image_height = int(fixed_shape_resizer['height'][0])\n",
    "\n",
    "    box_predictor = 'convolutional' if 'convolutional_box_predictor' in config['box_predictor'][0] else 'weight_shared_convolutional'\n",
    "\n",
    "    anchor_generator = config['anchor_generator'][0]\n",
    "    if 'ssd_anchor_generator' in anchor_generator:\n",
    "        ssd_anchor_generator = anchor_generator['ssd_anchor_generator'][0]\n",
    "        min_scale = float(ssd_anchor_generator['min_scale'][0])\n",
    "        max_scale = float(ssd_anchor_generator['max_scale'][0])\n",
    "        num_layers = int(ssd_anchor_generator['num_layers'][0])\n",
    "        aspect_ratios = [float(ar) for ar in ssd_anchor_generator['aspect_ratios']]\n",
    "        reduce_boxes_in_lowest_layer = True\n",
    "        if 'reduce_boxes_in_lowest_layer' in ssd_anchor_generator:\n",
    "            reduce_boxes_in_lowest_layer = ssd_anchor_generator['reduce_boxes_in_lowest_layer'][0] == 'true'\n",
    "        priors_generator = SSDAnchorGenerator(min_scale, max_scale, num_layers,\n",
    "                                              aspect_ratios, reduce_boxes_in_lowest_layer,\n",
    "                                              image_width, image_height)\n",
    "\n",
    "\n",
    "        print('Scale: [%f-%f]' % (min_scale, max_scale))\n",
    "        print('Aspect ratios: %s' % str(aspect_ratios))\n",
    "        print('Reduce boxes in the lowest layer: %s' % str(reduce_boxes_in_lowest_layer))\n",
    "    elif 'multiscale_anchor_generator' in anchor_generator:\n",
    "        multiscale_anchor_generator = anchor_generator['multiscale_anchor_generator'][0]\n",
    "        min_level = int(multiscale_anchor_generator['min_level'][0])\n",
    "        max_level = int(multiscale_anchor_generator['max_level'][0])\n",
    "        anchor_scale = float(multiscale_anchor_generator['anchor_scale'][0])\n",
    "        aspect_ratios = [float(ar) for ar in multiscale_anchor_generator['aspect_ratios']]\n",
    "        scales_per_octave = int(multiscale_anchor_generator['scales_per_octave'][0])\n",
    "        num_layers = max_level - min_level + 1\n",
    "        priors_generator = MultiscaleAnchorGenerator(min_level, aspect_ratios,\n",
    "                                                     scales_per_octave, anchor_scale)\n",
    "        print('Levels: [%d-%d]' % (min_level, max_level))\n",
    "        print('Anchor scale: %f' % anchor_scale)\n",
    "        print('Scales per octave: %d' % scales_per_octave)\n",
    "        print('Aspect ratios: %s' % str(aspect_ratios))\n",
    "    else:\n",
    "        print('Unknown anchor_generator')\n",
    "        exit(0)\n",
    "\n",
    "    print('Number of classes: %d' % num_classes)\n",
    "    print('Number of layers: %d' % num_layers)\n",
    "    print('box predictor: %s' % box_predictor)\n",
    "    print('Input image size: %dx%d' % (image_width, image_height))\n",
    "\n",
    "    # Read the graph.\n",
    "    outNames = ['num_detections', 'detection_scores', 'detection_boxes', 'detection_classes']\n",
    "\n",
    "    writeTextGraph(modelPath, outputPath, outNames)\n",
    "    graph_def = parseTextGraph(outputPath)\n",
    "\n",
    "    def getUnconnectedNodes():\n",
    "        unconnected = []\n",
    "        for node in graph_def.node:\n",
    "            unconnected.append(node.name)\n",
    "            for inp in node.input:\n",
    "                if inp in unconnected:\n",
    "                    unconnected.remove(inp)\n",
    "        return unconnected\n",
    "\n",
    "\n",
    "    def fuse_nodes(nodesToKeep):\n",
    "        # Detect unfused batch normalization nodes and fuse them.\n",
    "        # Add_0 <-- moving_variance, add_y\n",
    "        # Rsqrt <-- Add_0\n",
    "        # Mul_0 <-- Rsqrt, gamma\n",
    "        # Mul_1 <-- input, Mul_0\n",
    "        # Mul_2 <-- moving_mean, Mul_0\n",
    "        # Sub_0 <-- beta, Mul_2\n",
    "        # Add_1 <-- Mul_1, Sub_0\n",
    "        nodesMap = {node.name: node for node in graph_def.node}\n",
    "        subgraphBatchNorm = ['Add',\n",
    "            ['Mul', 'input', ['Mul', ['Rsqrt', ['Add', 'moving_variance', 'add_y']], 'gamma']],\n",
    "            ['Sub', 'beta', ['Mul', 'moving_mean', 'Mul_0']]]\n",
    "        subgraphBatchNormV2 = ['AddV2',\n",
    "            ['Mul', 'input', ['Mul', ['Rsqrt', ['AddV2', 'moving_variance', 'add_y']], 'gamma']],\n",
    "            ['Sub', 'beta', ['Mul', 'moving_mean', 'Mul_0']]]\n",
    "        # Detect unfused nearest neighbor resize.\n",
    "        subgraphResizeNN = ['Reshape',\n",
    "            ['Mul', ['Reshape', 'input', ['Pack', 'shape_1', 'shape_2', 'shape_3', 'shape_4', 'shape_5']],\n",
    "                    'ones'],\n",
    "            ['Pack', ['StridedSlice', ['Shape', 'input'], 'stack', 'stack_1', 'stack_2'],\n",
    "                     'out_height', 'out_width', 'out_channels']]\n",
    "        def checkSubgraph(node, targetNode, inputs, fusedNodes):\n",
    "            op = targetNode[0]\n",
    "            if node.op == op and (len(node.input) >= len(targetNode) - 1):\n",
    "                fusedNodes.append(node)\n",
    "                for i, inpOp in enumerate(targetNode[1:]):\n",
    "                    if isinstance(inpOp, list):\n",
    "                        if not node.input[i] in nodesMap or \\\n",
    "                           not checkSubgraph(nodesMap[node.input[i]], inpOp, inputs, fusedNodes):\n",
    "                            return False\n",
    "                    else:\n",
    "                        inputs[inpOp] = node.input[i]\n",
    "\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        nodesToRemove = []\n",
    "        for node in graph_def.node:\n",
    "            inputs = {}\n",
    "            fusedNodes = []\n",
    "            if checkSubgraph(node, subgraphBatchNorm, inputs, fusedNodes) or \\\n",
    "               checkSubgraph(node, subgraphBatchNormV2, inputs, fusedNodes):\n",
    "                name = node.name\n",
    "                node.Clear()\n",
    "                node.name = name\n",
    "                node.op = 'FusedBatchNorm'\n",
    "                node.input.append(inputs['input'])\n",
    "                node.input.append(inputs['gamma'])\n",
    "                node.input.append(inputs['beta'])\n",
    "                node.input.append(inputs['moving_mean'])\n",
    "                node.input.append(inputs['moving_variance'])\n",
    "                node.addAttr('epsilon', 0.001)\n",
    "                nodesToRemove += fusedNodes[1:]\n",
    "\n",
    "            inputs = {}\n",
    "            fusedNodes = []\n",
    "            if checkSubgraph(node, subgraphResizeNN, inputs, fusedNodes):\n",
    "                name = node.name\n",
    "                node.Clear()\n",
    "                node.name = name\n",
    "                node.op = 'ResizeNearestNeighbor'\n",
    "                node.input.append(inputs['input'])\n",
    "                node.input.append(name + '/output_shape')\n",
    "\n",
    "                out_height_node = nodesMap[inputs['out_height']]\n",
    "                out_width_node = nodesMap[inputs['out_width']]\n",
    "                out_height = int(out_height_node.attr['value']['tensor'][0]['int_val'][0])\n",
    "                out_width = int(out_width_node.attr['value']['tensor'][0]['int_val'][0])\n",
    "\n",
    "                shapeNode = NodeDef()\n",
    "                shapeNode.name = name + '/output_shape'\n",
    "                shapeNode.op = 'Const'\n",
    "                shapeNode.addAttr('value', [out_height, out_width])\n",
    "                graph_def.node.insert(graph_def.node.index(node), shapeNode)\n",
    "                nodesToKeep.append(shapeNode.name)\n",
    "\n",
    "                nodesToRemove += fusedNodes[1:]\n",
    "        for node in nodesToRemove:\n",
    "            graph_def.node.remove(node)\n",
    "\n",
    "    nodesToKeep = []\n",
    "    fuse_nodes(nodesToKeep)\n",
    "\n",
    "    removeIdentity(graph_def)\n",
    "\n",
    "    def to_remove(name, op):\n",
    "        return (not name in nodesToKeep) and \\\n",
    "               (op == 'Const' or (not op in keepOps) or name.startswith(prefixesToRemove))\n",
    "\n",
    "    removeUnusedNodesAndAttrs(to_remove, graph_def)\n",
    "\n",
    "\n",
    "    # Connect input node to the first layer\n",
    "    assert(graph_def.node[0].op == 'Placeholder')\n",
    "    try:\n",
    "        input_shape = graph_def.node[0].attr['shape']['shape'][0]['dim']\n",
    "        input_shape[1]['size'] = image_height\n",
    "        input_shape[2]['size'] = image_width\n",
    "    except:\n",
    "        print(\"Input shapes are undefined\")\n",
    "    # assert(graph_def.node[1].op == 'Conv2D')\n",
    "    weights = graph_def.node[1].input[-1]\n",
    "    for i in range(len(graph_def.node[1].input)):\n",
    "        graph_def.node[1].input.pop()\n",
    "    graph_def.node[1].input.append(graph_def.node[0].name)\n",
    "    graph_def.node[1].input.append(weights)\n",
    "\n",
    "    # check and correct the case when preprocessing block is after input\n",
    "    preproc_id = \"Preprocessor/\"\n",
    "    if graph_def.node[2].name.startswith(preproc_id) and \\\n",
    "        graph_def.node[2].input[0].startswith(preproc_id):\n",
    "\n",
    "        if not any(preproc_id in inp for inp in graph_def.node[3].input):\n",
    "            graph_def.node[3].input.insert(0, graph_def.node[2].name)\n",
    "\n",
    "\n",
    "    # Create SSD postprocessing head ###############################################\n",
    "\n",
    "    # Concatenate predictions of classes, predictions of bounding boxes and proposals.\n",
    "    def addConcatNode(name, inputs, axisNodeName):\n",
    "        concat = NodeDef()\n",
    "        concat.name = name\n",
    "        concat.op = 'ConcatV2'\n",
    "        for inp in inputs:\n",
    "            concat.input.append(inp)\n",
    "        concat.input.append(axisNodeName)\n",
    "        graph_def.node.extend([concat])\n",
    "\n",
    "    addConstNode('concat/axis_flatten', [-1], graph_def)\n",
    "    addConstNode('PriorBox/concat/axis', [-2], graph_def)\n",
    "\n",
    "    for label in ['ClassPredictor', 'BoxEncodingPredictor' if box_predictor is 'convolutional' else 'BoxPredictor']:\n",
    "        concatInputs = []\n",
    "        for i in range(num_layers):\n",
    "            # Flatten predictions\n",
    "            flatten = NodeDef()\n",
    "            if box_predictor is 'convolutional':\n",
    "                inpName = 'BoxPredictor_%d/%s/BiasAdd' % (i, label)\n",
    "            else:\n",
    "                if i == 0:\n",
    "                    inpName = 'WeightSharedConvolutionalBoxPredictor/%s/BiasAdd' % label\n",
    "                else:\n",
    "                    inpName = 'WeightSharedConvolutionalBoxPredictor_%d/%s/BiasAdd' % (i, label)\n",
    "            flatten.input.append(inpName)\n",
    "            flatten.name = inpName + '/Flatten'\n",
    "            flatten.op = 'Flatten'\n",
    "\n",
    "            concatInputs.append(flatten.name)\n",
    "            graph_def.node.extend([flatten])\n",
    "        addConcatNode('%s/concat' % label, concatInputs, 'concat/axis_flatten')\n",
    "\n",
    "    num_matched_layers = 0\n",
    "    for node in graph_def.node:\n",
    "        if re.match('BoxPredictor_\\d/BoxEncodingPredictor/convolution', node.name) or \\\n",
    "           re.match('BoxPredictor_\\d/BoxEncodingPredictor/Conv2D', node.name) or \\\n",
    "           re.match('WeightSharedConvolutionalBoxPredictor(_\\d)*/BoxPredictor/Conv2D', node.name):\n",
    "            node.addAttr('loc_pred_transposed', True)\n",
    "            num_matched_layers += 1\n",
    "    assert(num_matched_layers == num_layers)\n",
    "\n",
    "    # Add layers that generate anchors (bounding boxes proposals).\n",
    "    priorBoxes = []\n",
    "    boxCoder = config['box_coder'][0]\n",
    "    fasterRcnnBoxCoder = boxCoder['faster_rcnn_box_coder'][0]\n",
    "    boxCoderVariance = [1.0/float(fasterRcnnBoxCoder['x_scale'][0]), 1.0/float(fasterRcnnBoxCoder['y_scale'][0]), 1.0/float(fasterRcnnBoxCoder['width_scale'][0]), 1.0/float(fasterRcnnBoxCoder['height_scale'][0])]\n",
    "    for i in range(num_layers):\n",
    "        priorBox = NodeDef()\n",
    "        priorBox.name = 'PriorBox_%d' % i\n",
    "        priorBox.op = 'PriorBox'\n",
    "        if box_predictor is 'convolutional':\n",
    "            priorBox.input.append('BoxPredictor_%d/BoxEncodingPredictor/BiasAdd' % i)\n",
    "        else:\n",
    "            if i == 0:\n",
    "                priorBox.input.append('WeightSharedConvolutionalBoxPredictor/BoxPredictor/Conv2D')\n",
    "            else:\n",
    "                priorBox.input.append('WeightSharedConvolutionalBoxPredictor_%d/BoxPredictor/BiasAdd' % i)\n",
    "        priorBox.input.append(graph_def.node[0].name)  # image_tensor\n",
    "\n",
    "        priorBox.addAttr('flip', False)\n",
    "        priorBox.addAttr('clip', False)\n",
    "\n",
    "        widths, heights = priors_generator.get(i)\n",
    "\n",
    "        priorBox.addAttr('width', widths)\n",
    "        priorBox.addAttr('height', heights)\n",
    "        priorBox.addAttr('variance', boxCoderVariance)\n",
    "\n",
    "        graph_def.node.extend([priorBox])\n",
    "        priorBoxes.append(priorBox.name)\n",
    "\n",
    "    # Compare this layer's output with Postprocessor/Reshape\n",
    "    addConcatNode('PriorBox/concat', priorBoxes, 'concat/axis_flatten')\n",
    "\n",
    "    # Sigmoid for classes predictions and DetectionOutput layer\n",
    "    addReshape('ClassPredictor/concat', 'ClassPredictor/concat3d', [0, -1, num_classes + 1], graph_def)\n",
    "\n",
    "    sigmoid = NodeDef()\n",
    "    sigmoid.name = 'ClassPredictor/concat/sigmoid'\n",
    "    sigmoid.op = 'Sigmoid'\n",
    "    sigmoid.input.append('ClassPredictor/concat3d')\n",
    "    graph_def.node.extend([sigmoid])\n",
    "\n",
    "    addFlatten(sigmoid.name, sigmoid.name + '/Flatten', graph_def)\n",
    "\n",
    "    detectionOut = NodeDef()\n",
    "    detectionOut.name = 'detection_out'\n",
    "    detectionOut.op = 'DetectionOutput'\n",
    "\n",
    "    if box_predictor == 'convolutional':\n",
    "        detectionOut.input.append('BoxEncodingPredictor/concat')\n",
    "    else:\n",
    "        detectionOut.input.append('BoxPredictor/concat')\n",
    "    detectionOut.input.append(sigmoid.name + '/Flatten')\n",
    "    detectionOut.input.append('PriorBox/concat')\n",
    "\n",
    "    detectionOut.addAttr('num_classes', num_classes + 1)\n",
    "    detectionOut.addAttr('share_location', True)\n",
    "    detectionOut.addAttr('background_label_id', 0)\n",
    "\n",
    "    postProcessing = config['post_processing'][0]\n",
    "    batchNMS = postProcessing['batch_non_max_suppression'][0]\n",
    "\n",
    "    if 'iou_threshold' in batchNMS:\n",
    "        detectionOut.addAttr('nms_threshold', float(batchNMS['iou_threshold'][0]))\n",
    "    else:\n",
    "        detectionOut.addAttr('nms_threshold', 0.6)\n",
    "\n",
    "    if 'score_threshold' in batchNMS:\n",
    "        detectionOut.addAttr('confidence_threshold', float(batchNMS['score_threshold'][0]))\n",
    "    else:\n",
    "        detectionOut.addAttr('confidence_threshold', 0.01)\n",
    "\n",
    "    if 'max_detections_per_class' in batchNMS:\n",
    "        detectionOut.addAttr('top_k', int(batchNMS['max_detections_per_class'][0]))\n",
    "    else:\n",
    "        detectionOut.addAttr('top_k', 100)\n",
    "\n",
    "    if 'max_total_detections' in batchNMS:\n",
    "        detectionOut.addAttr('keep_top_k', int(batchNMS['max_total_detections'][0]))\n",
    "    else:\n",
    "        detectionOut.addAttr('keep_top_k', 100)\n",
    "\n",
    "    detectionOut.addAttr('code_type', \"CENTER_SIZE\")\n",
    "\n",
    "    graph_def.node.extend([detectionOut])\n",
    "\n",
    "    while True:\n",
    "        unconnectedNodes = getUnconnectedNodes()\n",
    "        unconnectedNodes.remove(detectionOut.name)\n",
    "        if not unconnectedNodes:\n",
    "            break\n",
    "\n",
    "        for name in unconnectedNodes:\n",
    "            for i in range(len(graph_def.node)):\n",
    "                if graph_def.node[i].name == name:\n",
    "                    del graph_def.node[i]\n",
    "                    break\n",
    "\n",
    "    # Save as text.\n",
    "    graph_def.save(outputPath)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Run this script to get a text graph of '\n",
    "                                                 'SSD model from TensorFlow Object Detection API. '\n",
    "                                                 'Then pass it with .pb file to cv::dnn::readNetFromTensorflow function.')\n",
    "    parser.add_argument('--input', required=True, help='Path to frozen TensorFlow graph.')\n",
    "    parser.add_argument('--output', required=True, help='Path to output text graph.')\n",
    "    parser.add_argument('--config', required=True, help='Path to a *.config file is used for training.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    createSSDGraph(args.input, args.config, args.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
